/*
 * Copyright (c) 2024 Alibaba Group Holding Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
syntax = "proto2";

package fluss;
option java_package = "com.alibaba.fluss.rpc.messages";
option optimize_for = LITE_RUNTIME;

// the message indicates a failed request of a server failure.
message ErrorResponse {
  required int32 error_code = 1;
  optional string error_message = 2;
}

message ApiVersionsRequest {
  required string client_software_name = 1;
  required string client_software_version = 2;
}

message ApiVersionsResponse {
  repeated PbApiVersion api_versions = 1;
}

// get schema request and response
message GetTableSchemaRequest {
  required PbTablePath table_path = 1;
  optional int32 schema_id = 2;
}

message GetTableSchemaResponse {
  required int32 schema_id = 1;
  required bytes schema_json = 2;
}

// create database request and response
message CreateDatabaseRequest {
  required string database_name = 1;
  required bool ignore_if_exists = 2;
}

message CreateDatabaseResponse {
}

// drop database request and response
message DropDatabaseRequest {
  required string database_name = 1;
  required bool ignore_if_not_exists = 2;
  required bool cascade = 3;
}
message DropDatabaseResponse {
}

// database exists request and response
message DatabaseExistsRequest {
  required string database_name = 1;
}
message DatabaseExistsResponse {
  required bool exists = 1;
}

// list databases request and response
message ListDatabasesRequest {
}
message ListDatabasesResponse {
  repeated string database_name = 1;
}

// create table request and response
message CreateTableRequest {
  required PbTablePath table_path = 1;
  required bytes table_json = 2;
  required bool ignore_if_exists = 3;
}

message CreateTableResponse {
}

// get table request and response
message GetTableRequest {
  required PbTablePath table_path = 1;
}

message GetTableResponse {
  required int64 table_id = 1;
  required int32 schema_id = 2;
  required bytes table_json = 3;
}

// list tables request and response
message ListTablesRequest {
  required string database_name = 1;
}

message ListTablesResponse {
  repeated string table_name = 1;
}

// drop table request and response
message DropTableRequest {
  required PbTablePath table_path = 1;
  required bool ignore_if_not_exists = 2;
}

message DropTableResponse {
}

// table exists request and response
message TableExistsRequest {
  required PbTablePath table_path = 1;
}

message TableExistsResponse {
  required bool exists = 1;
}

// metadata request and response, request send from client to each server.
message MetadataRequest {
  repeated PbTablePath table_path = 1;
  repeated PbPhysicalTablePath partitions_path = 2;

  // note: currently, we assume the partition ids must belong to the table_paths in the
  // metadata request
  // todo: we won't need the assumption after we introduce metadata cache in server
  repeated int64 partitions_id = 3 [packed = true];
}

message MetadataResponse {
  optional PbServerNode coordinator_server = 1;
  repeated PbServerNode tablet_servers = 2;
  repeated PbTableMetadata table_metadata = 3;
  repeated PbPartitionMetadata partition_metadata = 4;
}

// update metadata request and response, only send between server.
message UpdateMetadataRequest {
  optional PbServerNode coordinator_server = 1;
  repeated PbServerNode tablet_servers = 2;
  repeated PbTableMetadata table_metadata = 3;
}

message UpdateMetadataResponse {
}

// produce log request and response
message ProduceLogRequest {
  required int32 acks = 1;
  required int64 table_id = 2;
  required int32 timeout_ms = 3;
  repeated PbProduceLogReqForBucket buckets_req = 4;
}

message ProduceLogResponse {
  repeated PbProduceLogRespForBucket buckets_resp = 1;
}

// fetch log request and response
message FetchLogRequest {
  required int32 follower_server_id = 1;  // value -1 indicate the request from client.
  required int32 max_bytes = 2;
  repeated PbFetchLogReqForTable tables_req = 3;
}

message FetchLogResponse {
  repeated PbFetchLogRespForTable tables_resp = 1;
}

// put kv request and response
message PutKvRequest {
  required int32 acks = 1;
  required int64 table_id = 2;
  required int32 timeout_ms = 3;
  // the indexes for the columns to write,
  // if empty, means write all columns
  repeated int32 target_columns = 4 [packed = true];
  repeated PbPutKvReqForBucket buckets_req = 5;
}

message PutKvResponse {
  repeated PbPutKvRespForBucket buckets_resp = 1;
}

// lookup request and response
message LookupRequest {
  required int64 table_id = 1;
  repeated PbLookupReqForBucket buckets_req = 2;
}

message LookupResponse {
  repeated PbLookupRespForBucket buckets_resp = 1;
}

// Index Lookup request and response
message IndexLookupRequest {
  required int64 table_id = 1;
  repeated PbIndexLookupReqForBucket buckets_req = 2;
}

message IndexLookupResponse {
  repeated PbIndexLookupRespForBucket buckets_resp = 1;
}


// limit scan request and response
message LimitScanRequest {
  required int64 table_id = 2;
  optional int64 partition_id = 3;
  required int32 bucket_id = 4;
  required int32 limit = 5;
}

message LimitScanResponse{
  optional int32 error_code = 1;
  optional string error_message = 2;
  // flag to indicate the table type
  optional bool is_log_table = 3;
  // LogRecordBatch if is_log_table is true, otherwise KvRecordBatch
  optional bytes records = 4;
}


// notify bucket leader and isr request
message NotifyLeaderAndIsrRequest {
  required int32 coordinator_epoch = 1;
  repeated PbNotifyLeaderAndIsrReqForBucket notify_buckets_leader_req = 2;
}

// response for notify bucket leader and isr request
message NotifyLeaderAndIsrResponse {
  repeated PbNotifyLeaderAndIsrRespForBucket notify_buckets_leader_resp = 1;
}

// stop bucket replica request
message StopReplicaRequest {
  required int32 coordinator_epoch = 1;
  repeated PbStopReplicaReqForBucket stop_replicas_req = 2;
}

// response for stop bucket replica request
message StopReplicaResponse {
  repeated PbStopReplicaRespForBucket stop_replicas_resp = 1;
}

// adjust isr request and response
message AdjustIsrRequest {
  required int32 serverId = 1;
  repeated PbAdjustIsrReqForTable tables_req = 2;
}

message AdjustIsrResponse {
  repeated PbAdjustIsrRespForTable tables_resp = 1;
}

// list offsets request and response
message ListOffsetsRequest {
  required int32 follower_server_id = 1;  // value -1 indicate the request from client.
  required int32 offset_type = 2; // value can be 0,1,2 (see ListOffsetsParam for more details)
  required int64 table_id = 3;
  optional int64 partition_id = 4;
  repeated int32 bucket_id = 5 [packed = true]; // it is recommended to use packed for repeated numerics to get more efficient encoding
  optional int64 startTimestamp = 6;
}
message ListOffsetsResponse {
  repeated PbListOffsetsRespForBucket buckets_resp = 1;
}

// commit kv snapshot request and response
message CommitKvSnapshotRequest {
  required bytes completed_snapshot = 1;
  required int32 coordinator_epoch = 2;
  required int32 bucket_leader_epoch = 3;
}

message CommitKvSnapshotResponse {
}

// notify the log offset about kv snapshot
message NotifyKvSnapshotOffsetRequest {
  required int64 table_id = 1;
  optional int64 partition_id = 2;
  required int32 bucket_id = 3;
  required int32 coordinator_epoch = 4;
  required int64 min_retain_offset = 5;
}

message NotifyKvSnapshotOffsetResponse {
}

// get table kv snapshot request and response
message GetKvSnapshotRequest {
  required PbTablePath table_path = 1;
}

message GetKvSnapshotResponse {
  required int64 table_id = 1;
  repeated PbSnapshotForBucket bucket_snapshots = 2;
}

message GetLakeTableSnapshotRequest {
  required PbTablePath table_path = 1;
}

message GetLakeTableSnapshotResponse {
  required PbLakeStorageInfo lakehouse_storage_info = 1;
  required int64 table_id = 2;
  required int64 snapshotId = 3;
  repeated PbLakeSnapshotForBucket bucket_snapshots = 4;
}

message GetPartitionSnapshotRequest {
  required PbTablePath table_path = 1;
  required string partition_name = 2;
}

message GetPartitionSnapshotResponse {
  required int64 table_id = 1;
  required int64 partition_id = 2;
  repeated PbSnapshotForBucket bucket_snapshots = 3;
}

message GetFileSystemSecurityTokenRequest {
}

message GetFileSystemSecurityTokenResponse {
  required string schema = 1;
  required bytes token = 2;
  optional int64 expiration_time = 3;
  repeated PbKeyValue addition_info = 4;
}

message DescribeLakeStorageRequest {
}

message DescribeLakeStorageResponse {
  required PbLakeStorageInfo lakehouse_storage_info = 1;
}

// init writer request and response
message InitWriterRequest {
}

message InitWriterResponse {
  required int64 writer_id = 1;
}

message ListPartitionInfosRequest {
  required PbTablePath table_path = 1;
}

message ListPartitionInfosResponse {
  repeated PbPartitionInfo partitions_info = 1;
}

// commit remote log manifest request and response
message CommitRemoteLogManifestRequest {
  required int64 table_id = 1;
  optional int64 partition_id = 2;
  required int32 bucket_id = 3;
  required string remote_log_manifest_path = 4;
  required int64 remote_log_start_offset = 5;
  required int64 remote_log_end_offset = 6;
  required int32 coordinator_epoch = 7;
  required int32 bucket_leader_epoch = 8;
}

message CommitRemoteLogManifestResponse {
  required bool commitSuccess = 1;
}

// notify remote log offsets request and response
message NotifyRemoteLogOffsetsRequest {
  required int64 table_id = 1;
  optional int64 partition_id = 2;
  required int32 bucket_id = 3;
  required int32 coordinator_epoch = 4;
  required int64 remote_start_offset = 5;
  required int64 remote_end_offset = 6;
}

message NotifyRemoteLogOffsetsResponse {
}

message CommitLakeTableSnapshotRequest {
  repeated PbLakeTableSnapshotInfo tables_req = 1;
}

message PbLakeTableSnapshotInfo {
  optional int64 table_id = 1;
  required int64 snapshot_id = 2;
  repeated PbLakeTableOffsetForBucket buckets_req = 3;
}

message PbLakeTableOffsetForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  optional int64 log_start_offset = 3;
  optional int64 log_end_offset = 4;
}

message CommitLakeTableSnapshotResponse {
  repeated PbCommitLakeTableSnapshotRespForTable table_resp = 1;
}

message PbCommitLakeTableSnapshotRespForTable {
  required int64 table_id = 1;
  optional int32 error_code = 2;
  optional string error_message = 3;
}

message NotifyLakeTableOffsetRequest {
  required int32 coordinator_epoch = 1;
  repeated PbNotifyLakeTableOffsetReqForBucket notify_buckets_req = 2;
}

message PbNotifyLakeTableOffsetReqForBucket {
  required int64 table_id = 1;
  optional int64 partition_id = 2;
  required int32 bucket_id = 3;
  required int64 snapshot_id = 4;
  optional int64 log_start_offset = 5;
  optional int64 log_end_offset = 6;
}

message NotifyLakeTableOffsetResponse {
}

// --------------- Inner classes ----------------
message PbApiVersion {
  required int32 api_key = 1;
  required int32 min_version = 2;
  required int32 max_version = 3;
}

message PbTablePath {
  required string database_name = 1;
  required string table_name = 2;
}

message PbPhysicalTablePath {
  required string database_name = 1;
  required string table_name = 2;
  optional string partition_name = 3;
}

message PbServerNode {
  required int32 node_id = 1;
  required string host = 2;
  required int32 port = 3;
}

message PbTableMetadata {
  required PbTablePath table_path = 1;
  required int64 table_id = 2;
  required int32 schema_id = 3;
  required bytes table_json = 4;
  repeated PbBucketMetadata bucket_metadata = 5;
}

message PbPartitionMetadata {
  required int64 table_id = 1;
  // the partition name and id for the partition
  required string partition_name = 2;
  required int64 partition_id = 3;
  repeated PbBucketMetadata bucket_metadata = 4;
}

message PbBucketMetadata {
  required int32 bucket_id = 1;
  // optional as some time the leader may not elected yet
  optional int32 leader_id = 2;
  repeated int32 replica_id = 3 [packed = true];
  // TODO: Add isr here.
}

message PbProduceLogReqForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  required bytes records = 3;
}

message PbProduceLogRespForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  optional int32 error_code = 3;
  optional string error_message = 4;
  optional int64 base_offset = 5;
}

message PbFetchLogReqForTable {
  required int64 table_id = 1;
  required bool projection_pushdown_enabled = 2;
  repeated int32 projected_fields = 3 [packed = true];
  repeated PbFetchLogReqForBucket buckets_req = 4;
}

message PbFetchLogReqForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  // TODO leader epoch
  required int64 fetch_offset = 3;
  required int32 max_fetch_bytes = 4;
}

message PbFetchLogRespForTable {
  required int64 table_id = 1;
  repeated PbFetchLogRespForBucket buckets_resp = 2;
}
message PbFetchLogRespForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  optional int32 error_code = 3;
  optional string error_message = 4;
  optional int64 high_watermark = 5;
  optional int64 log_start_offset = 6; // TODO now we don't introduce log start offset, but remain it in protobuf
  optional PbRemoteLogFetchInfo remote_log_fetch_info = 7;
  optional bytes records = 8;
}

message PbPutKvReqForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  required bytes records = 3;
}

message PbPutKvRespForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  optional int32 error_code = 3;
  optional string error_message = 4;
}

message PbLookupReqForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  repeated bytes keys = 3;
}

message PbLookupRespForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  optional int32 error_code = 3;
  optional string error_message = 4;
  repeated PbValue values = 5;
}

message PbValue {
  // optional, if empty, means no value
  optional bytes values = 1;
}

message PbIndexLookupReqForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  repeated bytes keys = 3;
}

message PbIndexData {
  required string index_name = 1;
  required bytes index_key = 2;
}

message PbIndexLookupRespForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  repeated PbIndexLookupRespForKey keys_resp = 3;
}

message PbIndexLookupRespForKey {
  repeated bytes values = 1;
}

message PbTableBucket {
  required int64 table_id = 1;
  optional int64 partition_id = 2;
  required int32 bucket_id = 3;
}

message PbAdjustIsrReqForTable {
  required int64 table_id = 1;
  repeated PbAdjustIsrReqForBucket buckets_req = 2;
}


message PbAdjustIsrReqForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  required int32 leader_epoch = 3;
  repeated int32 new_isr = 4 [packed = true];
  required int32 coordinator_epoch = 5;
  required int32 bucket_epoch = 6;
}

message PbAdjustIsrRespForTable {
  required int64 table_id = 1;
  repeated PbAdjustIsrRespForBucket buckets_resp = 2;
}

message PbAdjustIsrRespForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  optional int32 error_code = 3;
  optional string error_message = 4;
  optional int32 leader_id = 5;
  optional int32 leader_epoch = 6;
  repeated int32 isr = 7 [packed = true];
  optional int32 bucket_epoch = 8;
  optional int32 coordinator_epoch = 9;
}

message PbListOffsetsRespForBucket {
  required int32 bucket_id = 1;
  optional int32 error_code = 2;
  optional string error_message = 3;
  optional int64 offset = 4;
}

message PbNotifyLeaderAndIsrReqForBucket {
  // we need table path for tablet server to create data dir for the bucket,
  // although tablet server don't need it after it has created data dir.
  // For simplicity, we always pass table path.
  required PbPhysicalTablePath physical_table_path = 1;
  required PbTableBucket table_bucket = 2;
  required int32 leader = 3;
  required int32 leader_epoch = 4;
  repeated int32 replicas = 5 [packed = true];
  repeated int32 isr = 6 [packed = true];
  required int32 bucket_epoch = 7;
}

message PbNotifyLeaderAndIsrRespForBucket {
  required PbTableBucket table_bucket = 1;
  optional int32 error_code = 2;
  optional string error_message = 3;
}

message PbStopReplicaReqForBucket {
  required PbTableBucket table_bucket = 1;
  required int32 leader_epoch = 2;
  required bool delete = 3;
}

message PbStopReplicaRespForBucket {
  required PbTableBucket table_bucket = 1;
  optional int32 error_code = 2;
  optional string error_message = 3;
}

message PbSnapshotForBucket {
  required int32 bucket_id = 1;
  // empty if no any snapshot for the bucket
  optional PbBucketSnapshot snapshot = 2;
}

message PbLakeSnapshotForBucket {
  optional int64 partition_id = 1;
  required int32 bucket_id = 2;
  optional int64 log_offset = 3;
}

message PbBucketSnapshot {
  required int64 log_offset = 1;
  repeated PbRemotePathAndLocalFile snapshot_files = 2;
}

message PbRemotePathAndLocalFile {
  required string remote_path = 1;
  required string local_file_name = 2;
}

message PbKeyValue {
  required string key = 1;
  required string value = 2;
}

message PbRemoteLogFetchInfo {
  required string remote_log_tablet_dir = 1;
  optional string partition_name = 2;
  repeated PbRemoteLogSegment remote_log_segments = 3;
  optional int32 first_start_pos = 4;
}

message PbRemoteLogSegment {
  required string remote_log_segment_id = 1;
  required int64 remote_log_start_offset = 2;
  required int64 remote_log_end_offset = 3;
  required int32 segment_size_in_bytes = 4;
}

message PbPartitionInfo {
  required int64 partition_id = 1;
  required string partition_name = 2;
}

message PbLakeStorageInfo {
  required string lake_storage_type = 1;
  repeated PbKeyValue catalog_properties = 2;
}